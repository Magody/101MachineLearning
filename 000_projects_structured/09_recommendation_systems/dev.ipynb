{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating\n",
       "0        0        0       5\n",
       "1        0        1       5\n",
       "2        0        2       5\n",
       "3        1        0       4\n",
       "4        1        1       5"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Datos de ejemplo\n",
    "#data = {\n",
    "#    'user_id': [6, 3, 7, 4, 6, 9, 2, 6, 7, 4, 3, 7, 7, 2, 5, 4, 1, 7, 5, 1, 4, 0, 9, 5, 8, 0, 9, 2, 6, 3, 8, 2, 4, 2, 6, 4, 8, 6, 1, 3, 8, 1, 9, 8, 9, 4, 1, 3, 6, 7],\n",
    "#    'book_id': [14, 2, 13, 16, 3, 17, 7, 3, 1, 5, 9, 3, 17, 11, 1, 9, 3, 13, 15, 14, 7, 13, 7, 15, 12, 17, 14, 12, 8, 14, 12, 0, 6, 8, 0, 11, 7, 10, 18, 16, 7, 2, 2, 0, 4, 9, 6, 8, 6, 8],\n",
    "#    'rating': [4, 2, 1, 5, 3, 4, 3, 3, 1, 3, 5, 3, 1, 5, 2, 3, 1, 2, 2, 4, 5, 3, 1, 4, 5, 4, 5, 5, 3, 5, 4, 5, 3, 3, 4, 2, 2, 5, 1, 5, 4, 4, 4, 4, 4, 3, 2, 4, 1, 1]\n",
    "#}\n",
    "\n",
    "data = {\n",
    "   'user_id': [0, 0, 0, 1, 1, 2, 2, 3],\n",
    "   'book_id': [1, 2, 3, 1, 2, 1, 4, 4],\n",
    "   'rating': [5, 5, 5, 4, 5, 5, 1, 1]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['book_id'] = df['book_id'] - 1\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 50: Train Loss = 22.157644271850586, Val Loss = 9.570460319519043\n",
      "Iteration 100: Train Loss = 39.007598876953125, Val Loss = 9.977509498596191\n",
      "Iteration 150: Train Loss = 28.808055877685547, Val Loss = 10.330760955810547\n",
      "Iteration 200: Train Loss = 16.950908660888672, Val Loss = 10.694851875305176\n",
      "Iteration 250: Train Loss = 14.156436920166016, Val Loss = 11.050032615661621\n",
      "Iteration 300: Train Loss = 10.15026569366455, Val Loss = 11.324319839477539\n",
      "Iteration 350: Train Loss = 15.977347373962402, Val Loss = 11.579676628112793\n",
      "Iteration 400: Train Loss = 5.192596912384033, Val Loss = 11.779767990112305\n",
      "Iteration 450: Train Loss = 13.144760131835938, Val Loss = 11.948722839355469\n",
      "Iteration 500: Train Loss = 9.791438102722168, Val Loss = 12.103989601135254\n",
      "TEST LOSS 27.674719\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "# Definición del modelo y las funciones auxiliares\n",
    "def buildSparseTensorRatings(df, dense_shape):\n",
    "    return tf.sparse.SparseTensor(\n",
    "        indices=df[['user_id', 'book_id']].values,\n",
    "        values=df['rating'].values,\n",
    "        dense_shape=dense_shape\n",
    "    )\n",
    "\n",
    "class CFModel:\n",
    "    def __init__(self, embeddings, l2_reg=0.01, dropout_rate=0.5):\n",
    "        self.embeddings = embeddings\n",
    "        self.l2_reg = l2_reg\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def train(self, tensor_train, tensor_val, num_iterations=1000, learning_rate=0.01, verbosity=1):\n",
    "        U = self.embeddings['user']\n",
    "        V = self.embeddings['item']\n",
    "\n",
    "        optimizer = tf.optimizers.Adam(learning_rate)\n",
    "\n",
    "        for i in range(num_iterations):\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Aplicar dropout a los embeddings\n",
    "                U_dropped = tf.nn.dropout(U, rate=self.dropout_rate)\n",
    "                V_dropped = tf.nn.dropout(V, rate=self.dropout_rate)\n",
    "                \n",
    "                # Predicciones\n",
    "                pred = tf.reduce_sum(\n",
    "                    tf.gather(U_dropped, tensor_train.indices[:, 0]) *\n",
    "                    tf.gather(V_dropped, tensor_train.indices[:, 1]), axis=1)\n",
    "\n",
    "                # Cálculo de la pérdida con regularización L2\n",
    "                loss = tf.reduce_mean(tf.square(tensor_train.values - pred)) + \\\n",
    "                       self.l2_reg * (tf.nn.l2_loss(U) + tf.nn.l2_loss(V))\n",
    "\n",
    "            grads = tape.gradient(loss, [U, V])\n",
    "            optimizer.apply_gradients(zip(grads, [U, V]))\n",
    "\n",
    "            if verbosity > 0 and (i + 1) % (num_iterations // 10) == 0:\n",
    "                val_loss = self.evaluate_loss(tensor_val)\n",
    "                print(f\"Iteration {i + 1}: Train Loss = {loss.numpy()}, Val Loss = {val_loss}\")\n",
    "\n",
    "        self.embeddings['user'] = U\n",
    "        self.embeddings['item'] = V\n",
    "\n",
    "        return U, V\n",
    "\n",
    "    def evaluate_loss(self, tensor):\n",
    "        U = self.embeddings['user']\n",
    "        V = self.embeddings['item']\n",
    "        \n",
    "        pred = tf.reduce_sum(tf.gather(U, tensor.indices[:, 0]) * tf.gather(V, tensor.indices[:, 1]), axis=1)\n",
    "        loss = tf.reduce_mean(tf.square(tensor.values - pred)) + \\\n",
    "               self.l2_reg * (tf.nn.l2_loss(U) + tf.nn.l2_loss(V))\n",
    "        \n",
    "        return loss.numpy()\n",
    "\n",
    "    def predict(self, user_id, item_id):\n",
    "        U = self.embeddings['user']\n",
    "        V = self.embeddings['item']\n",
    "        \n",
    "        user_embedding = tf.gather(U, user_id)\n",
    "        item_embedding = tf.gather(V, item_id)\n",
    "        prediction = tf.reduce_sum(user_embedding * item_embedding, axis=1)\n",
    "\n",
    "        return prediction.numpy()\n",
    "\n",
    "    def candidateGeneration(self, user_id, top_k=5):\n",
    "        U = self.embeddings['user']\n",
    "        V = self.embeddings['item']\n",
    "\n",
    "        user_embedding = tf.gather(U, user_id)\n",
    "\n",
    "        scores = tf.matmul(V, tf.expand_dims(user_embedding, axis=1))\n",
    "        scores = tf.squeeze(scores)\n",
    "\n",
    "        top_items = tf.argsort(scores, direction='DESCENDING')[:top_k]\n",
    "\n",
    "        return top_items.numpy()\n",
    "\n",
    "def buildModel(df_ratings: pd.DataFrame, embedding_dim=30, init_stddev=1, num_iterations=500, learning_rate=0.03, verbosity=1, l2_reg=0.01, dropout_rate=0.5):\n",
    "    \"\"\"\n",
    "    df_ratings: tiene columnas [\"user_id\",\"book_id\",\"rating\"]\n",
    "    \"\"\"\n",
    "\n",
    "    dense_shape = [df_ratings[\"user_id\"].max()+1, df_ratings[\"book_id\"].max()+1]\n",
    "\n",
    "    # Separar el DataFrame en train, validation y test\n",
    "    X_train, X_val, X_test = np.split(\n",
    "        df_ratings.sample(frac=1, replace=False).astype('float32'),\n",
    "        [int(.6*len(df_ratings)), int(.8*len(df_ratings))]\n",
    "    )\n",
    "\n",
    "    # Representación SparseTensor del conjunto de datos de entrenamiento, validación y prueba\n",
    "    tensor_train = buildSparseTensorRatings(X_train, dense_shape)\n",
    "    tensor_val = buildSparseTensorRatings(X_val, dense_shape)\n",
    "    tensor_test = buildSparseTensorRatings(X_test, dense_shape)\n",
    "\n",
    "    # Inicializar los embeddings usando una distribución normal\n",
    "    U = tf.Variable(tf.random.normal([tensor_train.dense_shape[0], embedding_dim], stddev=init_stddev), dtype=\"float32\")\n",
    "    V = tf.Variable(tf.random.normal([tensor_train.dense_shape[1], embedding_dim], stddev=init_stddev), dtype=\"float32\")\n",
    "\n",
    "    embeddings = {\n",
    "        \"user\": U,\n",
    "        \"item\": V\n",
    "    }\n",
    "\n",
    "    model = CFModel(embeddings, l2_reg=l2_reg, dropout_rate=dropout_rate)\n",
    "\n",
    "    U, V = model.train(tensor_train, tensor_val, num_iterations=num_iterations, learning_rate=learning_rate, verbosity=verbosity)\n",
    "\n",
    "    test_loss = model.evaluate_loss(tensor_test)\n",
    "    print(\"TEST LOSS\", test_loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Función para calcular el error cuadrático medio en el conjunto de prueba (opcional)\n",
    "def sparse_mean_square_error(U, V, tensor_test):\n",
    "    pred = tf.reduce_sum(tf.gather(U, tensor_test.indices[:, 0]) * tf.gather(V, tensor_test.indices[:, 1]), axis=1)\n",
    "    return tf.reduce_mean(tf.square(tensor_test.values - pred)).numpy()\n",
    "\n",
    "# Entrenar el modelo con los datos proporcionados\n",
    "model = buildModel(df, embedding_dim=30, init_stddev=1, num_iterations=500, learning_rate=0.001, l2_reg=0.01, dropout_rate=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating\n",
       "0        0        0       5\n",
       "1        0        1       5\n",
       "2        0        2       5\n",
       "3        1        0       4\n",
       "4        1        1       5\n",
       "5        2        0       5\n",
       "6        2        3       1\n",
       "7        3        3       1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-2.7330139>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id=0\n",
    "item_id=2\n",
    "self = model\n",
    "\n",
    "U = self.embeddings['user']\n",
    "V = self.embeddings['item']\n",
    "\n",
    "# Predicción para un par usuario-item\n",
    "user_embedding = tf.gather(U, user_id)\n",
    "item_embedding = tf.gather(V, item_id)\n",
    "prediction = tf.reduce_sum(user_embedding * item_embedding)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 recommendations for user 0: [0 2 3]\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "# Generar recomendaciones para el usuario 0\n",
    "top_items = model.candidateGeneration(user_id=0, top_k=top_k)\n",
    "print(f\"Top {top_k} recommendations for user 0: {top_items}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 12.7012 - val_loss: 11.0997\n",
      "Epoch 2/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 12.7153 - val_loss: 11.0895\n",
      "Epoch 3/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 12.5642 - val_loss: 11.0794\n",
      "Epoch 4/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 12.3895 - val_loss: 11.0692\n",
      "Epoch 5/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 12.5377 - val_loss: 11.0590\n",
      "Epoch 6/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 12.3062 - val_loss: 11.0488\n",
      "Epoch 7/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 12.4160 - val_loss: 11.0387\n",
      "Epoch 8/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 12.5787 - val_loss: 11.0286\n",
      "Epoch 9/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 13.0127 - val_loss: 11.0185\n",
      "Epoch 10/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 12.6350 - val_loss: 11.0086\n",
      "Epoch 11/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 12.5597 - val_loss: 10.9988\n",
      "Epoch 12/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 12.9057 - val_loss: 10.9891\n",
      "Epoch 13/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 12.7563 - val_loss: 10.9793\n",
      "Epoch 14/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 12.5025 - val_loss: 10.9696\n",
      "Epoch 15/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 12.6195 - val_loss: 10.9599\n",
      "Epoch 16/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 12.2655 - val_loss: 10.9504\n",
      "Epoch 17/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 12.5303 - val_loss: 10.9408\n",
      "Epoch 18/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 12.2861 - val_loss: 10.9310\n",
      "Epoch 19/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 12.6355 - val_loss: 10.9213\n",
      "Epoch 20/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 12.3549 - val_loss: 10.9118\n",
      "Epoch 21/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 12.5094 - val_loss: 10.9022\n",
      "Epoch 22/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 12.4455 - val_loss: 10.8928\n",
      "Epoch 23/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 12.3903 - val_loss: 10.8834\n",
      "Epoch 24/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 12.4658 - val_loss: 10.8738\n",
      "Epoch 25/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 12.1625 - val_loss: 10.8642\n",
      "Epoch 26/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 12.4807 - val_loss: 10.8545\n",
      "Epoch 27/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 12.3393 - val_loss: 10.8449\n",
      "Epoch 28/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 12.5496 - val_loss: 10.8355\n",
      "Epoch 29/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 12.0842 - val_loss: 10.8261\n",
      "Epoch 30/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 12.2734 - val_loss: 10.8165\n",
      "Epoch 31/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 12.0891 - val_loss: 10.8066\n",
      "Epoch 32/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 12.0373 - val_loss: 10.7968\n",
      "Epoch 33/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 11.7990 - val_loss: 10.7869\n",
      "Epoch 34/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 12.0488 - val_loss: 10.7770\n",
      "Epoch 35/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11.8534 - val_loss: 10.7668\n",
      "Epoch 36/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 11.9952 - val_loss: 10.7565\n",
      "Epoch 37/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 12.2696 - val_loss: 10.7462\n",
      "Epoch 38/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 12.1057 - val_loss: 10.7357\n",
      "Epoch 39/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 12.2216 - val_loss: 10.7253\n",
      "Epoch 40/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 12.0489 - val_loss: 10.7148\n",
      "Epoch 41/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 12.1027 - val_loss: 10.7043\n",
      "Epoch 42/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 12.1200 - val_loss: 10.6938\n",
      "Epoch 43/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 12.4159 - val_loss: 10.6833\n",
      "Epoch 44/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11.7992 - val_loss: 10.6727\n",
      "Epoch 45/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 12.2455 - val_loss: 10.6620\n",
      "Epoch 46/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 12.0941 - val_loss: 10.6512\n",
      "Epoch 47/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 12.3312 - val_loss: 10.6402\n",
      "Epoch 48/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11.8668 - val_loss: 10.6291\n",
      "Epoch 49/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11.6419 - val_loss: 10.6179\n",
      "Epoch 50/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11.9000 - val_loss: 10.6068\n",
      "Epoch 51/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 11.8953 - val_loss: 10.5959\n",
      "Epoch 52/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11.9183 - val_loss: 10.5849\n",
      "Epoch 53/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 11.5556 - val_loss: 10.5739\n",
      "Epoch 54/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 12.0619 - val_loss: 10.5627\n",
      "Epoch 55/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11.9590 - val_loss: 10.5513\n",
      "Epoch 56/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 11.8474 - val_loss: 10.5400\n",
      "Epoch 57/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11.4266 - val_loss: 10.5285\n",
      "Epoch 58/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11.6280 - val_loss: 10.5168\n",
      "Epoch 59/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 11.9363 - val_loss: 10.5049\n",
      "Epoch 60/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11.8180 - val_loss: 10.4930\n",
      "Epoch 61/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11.7961 - val_loss: 10.4812\n",
      "Epoch 62/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11.7550 - val_loss: 10.4693\n",
      "Epoch 63/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11.5376 - val_loss: 10.4571\n",
      "Epoch 64/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11.8301 - val_loss: 10.4450\n",
      "Epoch 65/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 11.8903 - val_loss: 10.4327\n",
      "Epoch 66/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11.3457 - val_loss: 10.4204\n",
      "Epoch 67/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11.1804 - val_loss: 10.4081\n",
      "Epoch 68/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 12.0244 - val_loss: 10.3956\n",
      "Epoch 69/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11.4836 - val_loss: 10.3832\n",
      "Epoch 70/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 12.0117 - val_loss: 10.3706\n",
      "Epoch 71/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 11.3797 - val_loss: 10.3578\n",
      "Epoch 72/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 11.5436 - val_loss: 10.3449\n",
      "Epoch 73/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 12.0027 - val_loss: 10.3317\n",
      "Epoch 74/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 11.6396 - val_loss: 10.3184\n",
      "Epoch 75/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11.7613 - val_loss: 10.3052\n",
      "Epoch 76/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11.7640 - val_loss: 10.2920\n",
      "Epoch 77/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 12.1403 - val_loss: 10.2787\n",
      "Epoch 78/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11.2840 - val_loss: 10.2650\n",
      "Epoch 79/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11.6434 - val_loss: 10.2508\n",
      "Epoch 80/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 11.6395 - val_loss: 10.2364\n",
      "Epoch 81/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11.3495 - val_loss: 10.2214\n",
      "Epoch 82/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11.6312 - val_loss: 10.2061\n",
      "Epoch 83/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11.3237 - val_loss: 10.1907\n",
      "Epoch 84/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11.4412 - val_loss: 10.1751\n",
      "Epoch 85/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11.5012 - val_loss: 10.1595\n",
      "Epoch 86/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 11.2138 - val_loss: 10.1433\n",
      "Epoch 87/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11.3701 - val_loss: 10.1267\n",
      "Epoch 88/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 11.3411 - val_loss: 10.1100\n",
      "Epoch 89/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 11.5221 - val_loss: 10.0933\n",
      "Epoch 90/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11.5170 - val_loss: 10.0764\n",
      "Epoch 91/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 11.4131 - val_loss: 10.0598\n",
      "Epoch 92/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11.4840 - val_loss: 10.0433\n",
      "Epoch 93/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 11.6092 - val_loss: 10.0268\n",
      "Epoch 94/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 11.4039 - val_loss: 10.0106\n",
      "Epoch 95/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 11.2992 - val_loss: 9.9943\n",
      "Epoch 96/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 11.4130 - val_loss: 9.9779\n",
      "Epoch 97/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11.1970 - val_loss: 9.9614\n",
      "Epoch 98/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 11.2106 - val_loss: 9.9447\n",
      "Epoch 99/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 11.4931 - val_loss: 9.9280\n",
      "Epoch 100/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 11.1418 - val_loss: 9.9111\n",
      "Epoch 101/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 11.0326 - val_loss: 9.8938\n",
      "Epoch 102/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 10.6491 - val_loss: 9.8761\n",
      "Epoch 103/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 10.7088 - val_loss: 9.8584\n",
      "Epoch 104/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 10.8797 - val_loss: 9.8402\n",
      "Epoch 105/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 10.8377 - val_loss: 9.8216\n",
      "Epoch 106/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 10.8888 - val_loss: 9.8029\n",
      "Epoch 107/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 11.3072 - val_loss: 9.7841\n",
      "Epoch 108/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10.8268 - val_loss: 9.7652\n",
      "Epoch 109/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 10.7446 - val_loss: 9.7459\n",
      "Epoch 110/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 10.6276 - val_loss: 9.7263\n",
      "Epoch 111/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 10.6420 - val_loss: 9.7063\n",
      "Epoch 112/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 10.6655 - val_loss: 9.6859\n",
      "Epoch 113/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10.8738 - val_loss: 9.6655\n",
      "Epoch 114/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 10.6398 - val_loss: 9.6452\n",
      "Epoch 115/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 10.5860 - val_loss: 9.6250\n",
      "Epoch 116/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 10.7048 - val_loss: 9.6048\n",
      "Epoch 117/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11.0624 - val_loss: 9.5844\n",
      "Epoch 118/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 10.6113 - val_loss: 9.5639\n",
      "Epoch 119/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10.8407 - val_loss: 9.5434\n",
      "Epoch 120/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 11.0481 - val_loss: 9.5232\n",
      "Epoch 121/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 10.9079 - val_loss: 9.5033\n",
      "Epoch 122/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 10.6558 - val_loss: 9.4834\n",
      "Epoch 123/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 10.6886 - val_loss: 9.4635\n",
      "Epoch 124/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 10.6119 - val_loss: 9.4429\n",
      "Epoch 125/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10.4705 - val_loss: 9.4217\n",
      "Epoch 126/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 10.6508 - val_loss: 9.4000\n",
      "Epoch 127/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 10.1809 - val_loss: 9.3780\n",
      "Epoch 128/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10.6201 - val_loss: 9.3557\n",
      "Epoch 129/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10.2370 - val_loss: 9.3332\n",
      "Epoch 130/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 10.4066 - val_loss: 9.3105\n",
      "Epoch 131/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 10.2294 - val_loss: 9.2879\n",
      "Epoch 132/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10.4614 - val_loss: 9.2652\n",
      "Epoch 133/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 10.3559 - val_loss: 9.2426\n",
      "Epoch 134/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10.0849 - val_loss: 9.2195\n",
      "Epoch 135/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10.3952 - val_loss: 9.1963\n",
      "Epoch 136/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10.7854 - val_loss: 9.1731\n",
      "Epoch 137/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10.2172 - val_loss: 9.1502\n",
      "Epoch 138/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 10.6416 - val_loss: 9.1272\n",
      "Epoch 139/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 10.2990 - val_loss: 9.1044\n",
      "Epoch 140/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10.2405 - val_loss: 9.0813\n",
      "Epoch 141/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 10.0313 - val_loss: 9.0574\n",
      "Epoch 142/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10.0542 - val_loss: 9.0327\n",
      "Epoch 143/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 10.1621 - val_loss: 9.0073\n",
      "Epoch 144/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 9.8293 - val_loss: 8.9815\n",
      "Epoch 145/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.9184 - val_loss: 8.9555\n",
      "Epoch 146/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9.9566 - val_loss: 8.9296\n",
      "Epoch 147/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 9.8654 - val_loss: 8.9035\n",
      "Epoch 148/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.9767 - val_loss: 8.8774\n",
      "Epoch 149/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10.3695 - val_loss: 8.8512\n",
      "Epoch 150/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.9385 - val_loss: 8.8248\n",
      "Epoch 151/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.7930 - val_loss: 8.7977\n",
      "Epoch 152/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 9.8334 - val_loss: 8.7705\n",
      "Epoch 153/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.7930 - val_loss: 8.7434\n",
      "Epoch 154/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9.6296 - val_loss: 8.7160\n",
      "Epoch 155/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.6892 - val_loss: 8.6887\n",
      "Epoch 156/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.6958 - val_loss: 8.6614\n",
      "Epoch 157/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.7598 - val_loss: 8.6342\n",
      "Epoch 158/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.8438 - val_loss: 8.6070\n",
      "Epoch 159/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.4250 - val_loss: 8.5795\n",
      "Epoch 160/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.6025 - val_loss: 8.5520\n",
      "Epoch 161/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9.3128 - val_loss: 8.5243\n",
      "Epoch 162/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.4690 - val_loss: 8.4964\n",
      "Epoch 163/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 9.5885 - val_loss: 8.4683\n",
      "Epoch 164/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9.5590 - val_loss: 8.4402\n",
      "Epoch 165/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.3517 - val_loss: 8.4120\n",
      "Epoch 166/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.4300 - val_loss: 8.3835\n",
      "Epoch 167/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.2443 - val_loss: 8.3545\n",
      "Epoch 168/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.3916 - val_loss: 8.3254\n",
      "Epoch 169/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.1833 - val_loss: 8.2961\n",
      "Epoch 170/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 9.4916 - val_loss: 8.2665\n",
      "Epoch 171/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 9.0698 - val_loss: 8.2366\n",
      "Epoch 172/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.0305 - val_loss: 8.2059\n",
      "Epoch 173/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9.1140 - val_loss: 8.1749\n",
      "Epoch 174/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.1617 - val_loss: 8.1437\n",
      "Epoch 175/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.0534 - val_loss: 8.1128\n",
      "Epoch 176/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8.8332 - val_loss: 8.0819\n",
      "Epoch 177/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8.8912 - val_loss: 8.0506\n",
      "Epoch 178/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 8.7138 - val_loss: 8.0190\n",
      "Epoch 179/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 9.0495 - val_loss: 7.9875\n",
      "Epoch 180/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.9778 - val_loss: 7.9560\n",
      "Epoch 181/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.9027 - val_loss: 7.9245\n",
      "Epoch 182/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8.9509 - val_loss: 7.8929\n",
      "Epoch 183/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.6075 - val_loss: 7.8609\n",
      "Epoch 184/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 9.0498 - val_loss: 7.8287\n",
      "Epoch 185/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8.8324 - val_loss: 7.7968\n",
      "Epoch 186/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8.6476 - val_loss: 7.7648\n",
      "Epoch 187/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 8.7050 - val_loss: 7.7329\n",
      "Epoch 188/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.0177 - val_loss: 7.7014\n",
      "Epoch 189/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.4900 - val_loss: 7.6702\n",
      "Epoch 190/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8.4704 - val_loss: 7.6389\n",
      "Epoch 191/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8.6829 - val_loss: 7.6074\n",
      "Epoch 192/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8.6614 - val_loss: 7.5757\n",
      "Epoch 193/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.4633 - val_loss: 7.5439\n",
      "Epoch 194/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 8.2566 - val_loss: 7.5123\n",
      "Epoch 195/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.1417 - val_loss: 7.4805\n",
      "Epoch 196/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 8.3946 - val_loss: 7.4483\n",
      "Epoch 197/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 8.6417 - val_loss: 7.4164\n",
      "Epoch 198/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8.0746 - val_loss: 7.3842\n",
      "Epoch 199/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 8.2579 - val_loss: 7.3516\n",
      "Epoch 200/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.8975 - val_loss: 7.3190\n",
      "Epoch 201/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8.1356 - val_loss: 7.2863\n",
      "Epoch 202/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.0563 - val_loss: 7.2535\n",
      "Epoch 203/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8.0913 - val_loss: 7.2208\n",
      "Epoch 204/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.6976 - val_loss: 7.1879\n",
      "Epoch 205/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 7.7754 - val_loss: 7.1541\n",
      "Epoch 206/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.1436 - val_loss: 7.1204\n",
      "Epoch 207/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 8.0033 - val_loss: 7.0873\n",
      "Epoch 208/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.8559 - val_loss: 7.0546\n",
      "Epoch 209/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.7571 - val_loss: 7.0221\n",
      "Epoch 210/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.6783 - val_loss: 6.9894\n",
      "Epoch 211/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7.8343 - val_loss: 6.9561\n",
      "Epoch 212/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.7394 - val_loss: 6.9228\n",
      "Epoch 213/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.8968 - val_loss: 6.8898\n",
      "Epoch 214/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.7551 - val_loss: 6.8566\n",
      "Epoch 215/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.4454 - val_loss: 6.8226\n",
      "Epoch 216/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.6978 - val_loss: 6.7883\n",
      "Epoch 217/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.2537 - val_loss: 6.7536\n",
      "Epoch 218/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.5669 - val_loss: 6.7178\n",
      "Epoch 219/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.2388 - val_loss: 6.6817\n",
      "Epoch 220/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.4268 - val_loss: 6.6458\n",
      "Epoch 221/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7.4035 - val_loss: 6.6104\n",
      "Epoch 222/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.1071 - val_loss: 6.5749\n",
      "Epoch 223/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.3907 - val_loss: 6.5393\n",
      "Epoch 224/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.1723 - val_loss: 6.5039\n",
      "Epoch 225/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7.1961 - val_loss: 6.4685\n",
      "Epoch 226/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.0514 - val_loss: 6.4328\n",
      "Epoch 227/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7.2442 - val_loss: 6.3974\n",
      "Epoch 228/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.9852 - val_loss: 6.3626\n",
      "Epoch 229/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6.8766 - val_loss: 6.3275\n",
      "Epoch 230/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7.2108 - val_loss: 6.2925\n",
      "Epoch 231/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.7350 - val_loss: 6.2581\n",
      "Epoch 232/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.9094 - val_loss: 6.2236\n",
      "Epoch 233/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.7380 - val_loss: 6.1894\n",
      "Epoch 234/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.9221 - val_loss: 6.1556\n",
      "Epoch 235/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.4853 - val_loss: 6.1218\n",
      "Epoch 236/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.7700 - val_loss: 6.0876\n",
      "Epoch 237/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.5436 - val_loss: 6.0534\n",
      "Epoch 238/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 6.2724 - val_loss: 6.0195\n",
      "Epoch 239/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6.5799 - val_loss: 5.9856\n",
      "Epoch 240/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.5690 - val_loss: 5.9518\n",
      "Epoch 241/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.4228 - val_loss: 5.9182\n",
      "Epoch 242/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.0560 - val_loss: 5.8840\n",
      "Epoch 243/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.4545 - val_loss: 5.8497\n",
      "Epoch 244/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.2138 - val_loss: 5.8153\n",
      "Epoch 245/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6.1342 - val_loss: 5.7799\n",
      "Epoch 246/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.3602 - val_loss: 5.7442\n",
      "Epoch 247/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.1193 - val_loss: 5.7091\n",
      "Epoch 248/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6.2480 - val_loss: 5.6743\n",
      "Epoch 249/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.9207 - val_loss: 5.6395\n",
      "Epoch 250/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.0212 - val_loss: 5.6045\n",
      "Epoch 251/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.8755 - val_loss: 5.5694\n",
      "Epoch 252/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6.0283 - val_loss: 5.5344\n",
      "Epoch 253/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.8081 - val_loss: 5.4995\n",
      "Epoch 254/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.6652 - val_loss: 5.4642\n",
      "Epoch 255/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.6259 - val_loss: 5.4282\n",
      "Epoch 256/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.9619 - val_loss: 5.3927\n",
      "Epoch 257/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.7776 - val_loss: 5.3584\n",
      "Epoch 258/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.9308 - val_loss: 5.3247\n",
      "Epoch 259/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.7189 - val_loss: 5.2915\n",
      "Epoch 260/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.8311 - val_loss: 5.2592\n",
      "Epoch 261/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.7337 - val_loss: 5.2275\n",
      "Epoch 262/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.7869 - val_loss: 5.1961\n",
      "Epoch 263/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.4659 - val_loss: 5.1644\n",
      "Epoch 264/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.4975 - val_loss: 5.1315\n",
      "Epoch 265/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.6528 - val_loss: 5.0988\n",
      "Epoch 266/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.4250 - val_loss: 5.0668\n",
      "Epoch 267/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.5772 - val_loss: 5.0356\n",
      "Epoch 268/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.4546 - val_loss: 5.0047\n",
      "Epoch 269/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.2913 - val_loss: 4.9735\n",
      "Epoch 270/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.4333 - val_loss: 4.9428\n",
      "Epoch 271/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.1296 - val_loss: 4.9123\n",
      "Epoch 272/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.3639 - val_loss: 4.8816\n",
      "Epoch 273/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.1698 - val_loss: 4.8512\n",
      "Epoch 274/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.2200 - val_loss: 4.8206\n",
      "Epoch 275/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.1354 - val_loss: 4.7899\n",
      "Epoch 276/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.9588 - val_loss: 4.7590\n",
      "Epoch 277/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.9745 - val_loss: 4.7276\n",
      "Epoch 278/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.8404 - val_loss: 4.6954\n",
      "Epoch 279/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.8836 - val_loss: 4.6632\n",
      "Epoch 280/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.0200 - val_loss: 4.6318\n",
      "Epoch 281/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.6680 - val_loss: 4.6005\n",
      "Epoch 282/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.7774 - val_loss: 4.5691\n",
      "Epoch 283/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.7967 - val_loss: 4.5381\n",
      "Epoch 284/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.5064 - val_loss: 4.5067\n",
      "Epoch 285/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.7789 - val_loss: 4.4751\n",
      "Epoch 286/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.2083 - val_loss: 4.4434\n",
      "Epoch 287/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.6333 - val_loss: 4.4104\n",
      "Epoch 288/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.4411 - val_loss: 4.3781\n",
      "Epoch 289/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.4034 - val_loss: 4.3459\n",
      "Epoch 290/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.5075 - val_loss: 4.3142\n",
      "Epoch 291/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.6290 - val_loss: 4.2837\n",
      "Epoch 292/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.2779 - val_loss: 4.2540\n",
      "Epoch 293/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.2114 - val_loss: 4.2237\n",
      "Epoch 294/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.4834 - val_loss: 4.1935\n",
      "Epoch 295/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.3991 - val_loss: 4.1644\n",
      "Epoch 296/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.2403 - val_loss: 4.1358\n",
      "Epoch 297/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.3634 - val_loss: 4.1075\n",
      "Epoch 298/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.1533 - val_loss: 4.0799\n",
      "Epoch 299/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 4.3602 - val_loss: 4.0529\n",
      "Epoch 300/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.1670 - val_loss: 4.0266\n",
      "Epoch 301/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.0607 - val_loss: 4.0005\n",
      "Epoch 302/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.0147 - val_loss: 3.9741\n",
      "Epoch 303/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.8594 - val_loss: 3.9474\n",
      "Epoch 304/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.0863 - val_loss: 3.9204\n",
      "Epoch 305/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.9069 - val_loss: 3.8942\n",
      "Epoch 306/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.0218 - val_loss: 3.8677\n",
      "Epoch 307/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.0328 - val_loss: 3.8415\n",
      "Epoch 308/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.8166 - val_loss: 3.8159\n",
      "Epoch 309/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.8240 - val_loss: 3.7906\n",
      "Epoch 310/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.7617 - val_loss: 3.7656\n",
      "Epoch 311/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.8808 - val_loss: 3.7410\n",
      "Epoch 312/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.5810 - val_loss: 3.7163\n",
      "Epoch 313/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.7840 - val_loss: 3.6913\n",
      "Epoch 314/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.7831 - val_loss: 3.6671\n",
      "Epoch 315/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.6139 - val_loss: 3.6429\n",
      "Epoch 316/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.6153 - val_loss: 3.6185\n",
      "Epoch 317/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.3725 - val_loss: 3.5934\n",
      "Epoch 318/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.6079 - val_loss: 3.5677\n",
      "Epoch 319/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.4422 - val_loss: 3.5423\n",
      "Epoch 320/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.4201 - val_loss: 3.5167\n",
      "Epoch 321/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.3127 - val_loss: 3.4912\n",
      "Epoch 322/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.3952 - val_loss: 3.4661\n",
      "Epoch 323/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.5083 - val_loss: 3.4421\n",
      "Epoch 324/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.2611 - val_loss: 3.4187\n",
      "Epoch 325/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.2659 - val_loss: 3.3955\n",
      "Epoch 326/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.3449 - val_loss: 3.3727\n",
      "Epoch 327/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.0803 - val_loss: 3.3500\n",
      "Epoch 328/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.1734 - val_loss: 3.3267\n",
      "Epoch 329/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.2789 - val_loss: 3.3035\n",
      "Epoch 330/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.1552 - val_loss: 3.2809\n",
      "Epoch 331/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.2111 - val_loss: 3.2590\n",
      "Epoch 332/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.1451 - val_loss: 3.2376\n",
      "Epoch 333/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.1747 - val_loss: 3.2170\n",
      "Epoch 334/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.0502 - val_loss: 3.1971\n",
      "Epoch 335/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.9705 - val_loss: 3.1769\n",
      "Epoch 336/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.0471 - val_loss: 3.1561\n",
      "Epoch 337/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.9407 - val_loss: 3.1353\n",
      "Epoch 338/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.8414 - val_loss: 3.1149\n",
      "Epoch 339/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.8956 - val_loss: 3.0948\n",
      "Epoch 340/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.8378 - val_loss: 3.0750\n",
      "Epoch 341/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.9292 - val_loss: 3.0555\n",
      "Epoch 342/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.6979 - val_loss: 3.0363\n",
      "Epoch 343/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.9225 - val_loss: 3.0175\n",
      "Epoch 344/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.8984 - val_loss: 2.9999\n",
      "Epoch 345/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.7610 - val_loss: 2.9827\n",
      "Epoch 346/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.5930 - val_loss: 2.9652\n",
      "Epoch 347/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.8424 - val_loss: 2.9477\n",
      "Epoch 348/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.8707 - val_loss: 2.9310\n",
      "Epoch 349/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.6316 - val_loss: 2.9147\n",
      "Epoch 350/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.5939 - val_loss: 2.8979\n",
      "Epoch 351/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.4537 - val_loss: 2.8806\n",
      "Epoch 352/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.6607 - val_loss: 2.8625\n",
      "Epoch 353/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.3598 - val_loss: 2.8446\n",
      "Epoch 354/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.3859 - val_loss: 2.8264\n",
      "Epoch 355/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.5842 - val_loss: 2.8087\n",
      "Epoch 356/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.4858 - val_loss: 2.7920\n",
      "Epoch 357/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.4774 - val_loss: 2.7759\n",
      "Epoch 358/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.4024 - val_loss: 2.7602\n",
      "Epoch 359/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.4439 - val_loss: 2.7447\n",
      "Epoch 360/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.3683 - val_loss: 2.7290\n",
      "Epoch 361/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.4279 - val_loss: 2.7138\n",
      "Epoch 362/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.3301 - val_loss: 2.6995\n",
      "Epoch 363/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.4461 - val_loss: 2.6855\n",
      "Epoch 364/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.2860 - val_loss: 2.6716\n",
      "Epoch 365/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.2854 - val_loss: 2.6574\n",
      "Epoch 366/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.2793 - val_loss: 2.6434\n",
      "Epoch 367/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.3281 - val_loss: 2.6296\n",
      "Epoch 368/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.2603 - val_loss: 2.6161\n",
      "Epoch 369/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.2157 - val_loss: 2.6030\n",
      "Epoch 370/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.1320 - val_loss: 2.5898\n",
      "Epoch 371/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.0494 - val_loss: 2.5766\n",
      "Epoch 372/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.1644 - val_loss: 2.5637\n",
      "Epoch 373/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.1662 - val_loss: 2.5514\n",
      "Epoch 374/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.1736 - val_loss: 2.5399\n",
      "Epoch 375/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.0060 - val_loss: 2.5285\n",
      "Epoch 376/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.9815 - val_loss: 2.5162\n",
      "Epoch 377/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.9695 - val_loss: 2.5037\n",
      "Epoch 378/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.0119 - val_loss: 2.4922\n",
      "Epoch 379/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.0304 - val_loss: 2.4811\n",
      "Epoch 380/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.0847 - val_loss: 2.4706\n",
      "Epoch 381/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.9634 - val_loss: 2.4605\n",
      "Epoch 382/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.9558 - val_loss: 2.4503\n",
      "Epoch 383/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.9758 - val_loss: 2.4403\n",
      "Epoch 384/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.9006 - val_loss: 2.4307\n",
      "Epoch 385/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.9723 - val_loss: 2.4217\n",
      "Epoch 386/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.8620 - val_loss: 2.4126\n",
      "Epoch 387/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.8133 - val_loss: 2.4032\n",
      "Epoch 388/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.7830 - val_loss: 2.3935\n",
      "Epoch 389/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.8757 - val_loss: 2.3843\n",
      "Epoch 390/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.7453 - val_loss: 2.3751\n",
      "Epoch 391/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.8253 - val_loss: 2.3658\n",
      "Epoch 392/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.7452 - val_loss: 2.3572\n",
      "Epoch 393/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.8144 - val_loss: 2.3489\n",
      "Epoch 394/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.7302 - val_loss: 2.3403\n",
      "Epoch 395/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.8143 - val_loss: 2.3317\n",
      "Epoch 396/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.7363 - val_loss: 2.3239\n",
      "Epoch 397/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.7323 - val_loss: 2.3161\n",
      "Epoch 398/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.6524 - val_loss: 2.3080\n",
      "Epoch 399/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.6939 - val_loss: 2.2998\n",
      "Epoch 400/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.7291 - val_loss: 2.2926\n",
      "Epoch 401/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.6366 - val_loss: 2.2858\n",
      "Epoch 402/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.6856 - val_loss: 2.2793\n",
      "Epoch 403/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.6021 - val_loss: 2.2732\n",
      "Epoch 404/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.6127 - val_loss: 2.2667\n",
      "Epoch 405/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.5531 - val_loss: 2.2596\n",
      "Epoch 406/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.5715 - val_loss: 2.2518\n",
      "Epoch 407/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.6010 - val_loss: 2.2446\n",
      "Epoch 408/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.5636 - val_loss: 2.2375\n",
      "Epoch 409/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.4868 - val_loss: 2.2302\n",
      "Epoch 410/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.5316 - val_loss: 2.2222\n",
      "Epoch 411/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4943 - val_loss: 2.2148\n",
      "Epoch 412/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4385 - val_loss: 2.2082\n",
      "Epoch 413/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4855 - val_loss: 2.2016\n",
      "Epoch 414/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.4408 - val_loss: 2.1946\n",
      "Epoch 415/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.5446 - val_loss: 2.1885\n",
      "Epoch 416/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.5038 - val_loss: 2.1843\n",
      "Epoch 417/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.4456 - val_loss: 2.1802\n",
      "Epoch 418/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.4702 - val_loss: 2.1762\n",
      "Epoch 419/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4537 - val_loss: 2.1726\n",
      "Epoch 420/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.4039 - val_loss: 2.1684\n",
      "Epoch 421/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3968 - val_loss: 2.1635\n",
      "Epoch 422/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4017 - val_loss: 2.1586\n",
      "Epoch 423/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3950 - val_loss: 2.1541\n",
      "Epoch 424/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4115 - val_loss: 2.1491\n",
      "Epoch 425/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.3207 - val_loss: 2.1443\n",
      "Epoch 426/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.4100 - val_loss: 2.1392\n",
      "Epoch 427/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.3756 - val_loss: 2.1340\n",
      "Epoch 428/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.4411 - val_loss: 2.1291\n",
      "Epoch 429/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.2495 - val_loss: 2.1246\n",
      "Epoch 430/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.3504 - val_loss: 2.1205\n",
      "Epoch 431/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.3777 - val_loss: 2.1178\n",
      "Epoch 432/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.2118 - val_loss: 2.1159\n",
      "Epoch 433/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.2624 - val_loss: 2.1137\n",
      "Epoch 434/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.3327 - val_loss: 2.1114\n",
      "Epoch 435/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3123 - val_loss: 2.1089\n",
      "Epoch 436/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.2871 - val_loss: 2.1062\n",
      "Epoch 437/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2814 - val_loss: 2.1032\n",
      "Epoch 438/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.2042 - val_loss: 2.1005\n",
      "Epoch 439/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.2923 - val_loss: 2.0983\n",
      "Epoch 440/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2142 - val_loss: 2.0968\n",
      "Epoch 441/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.2509 - val_loss: 2.0957\n",
      "Epoch 442/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.2236 - val_loss: 2.0943\n",
      "Epoch 443/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.2221 - val_loss: 2.0919\n",
      "Epoch 444/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.2118 - val_loss: 2.0888\n",
      "Epoch 445/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2030 - val_loss: 2.0856\n",
      "Epoch 446/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.2181 - val_loss: 2.0831\n",
      "Epoch 447/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1949 - val_loss: 2.0811\n",
      "Epoch 448/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2041 - val_loss: 2.0797\n",
      "Epoch 449/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.2197 - val_loss: 2.0784\n",
      "Epoch 450/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2357 - val_loss: 2.0773\n",
      "Epoch 451/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.1596 - val_loss: 2.0766\n",
      "Epoch 452/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1629 - val_loss: 2.0751\n",
      "Epoch 453/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.1316 - val_loss: 2.0731\n",
      "Epoch 454/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.1323 - val_loss: 2.0711\n",
      "Epoch 455/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1344 - val_loss: 2.0692\n",
      "Epoch 456/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.1876 - val_loss: 2.0678\n",
      "Epoch 457/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.1283 - val_loss: 2.0667\n",
      "Epoch 458/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1428 - val_loss: 2.0661\n",
      "Epoch 459/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.1173 - val_loss: 2.0660\n",
      "Epoch 460/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1727 - val_loss: 2.0661\n",
      "Epoch 461/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1427 - val_loss: 2.0659\n",
      "Epoch 462/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1686 - val_loss: 2.0659\n",
      "Epoch 463/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0655 - val_loss: 2.0662\n",
      "Epoch 464/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1279 - val_loss: 2.0658\n",
      "Epoch 465/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0648 - val_loss: 2.0649\n",
      "Epoch 466/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.1146 - val_loss: 2.0641\n",
      "Epoch 467/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0938 - val_loss: 2.0645\n",
      "Epoch 468/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0444 - val_loss: 2.0646\n",
      "Epoch 469/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0637 - val_loss: 2.0646\n",
      "Epoch 470/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9880 - val_loss: 2.0649\n",
      "Epoch 471/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0430 - val_loss: 2.0655\n",
      "Epoch 472/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.0934 - val_loss: 2.0664\n",
      "Epoch 473/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0683 - val_loss: 2.0671\n",
      "Epoch 474/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0409 - val_loss: 2.0673\n",
      "Epoch 475/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0041 - val_loss: 2.0671\n",
      "Epoch 476/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0622 - val_loss: 2.0672\n",
      "Epoch 477/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0365 - val_loss: 2.0668\n",
      "Epoch 478/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.0197 - val_loss: 2.0656\n",
      "Epoch 479/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0635 - val_loss: 2.0643\n",
      "Epoch 480/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9816 - val_loss: 2.0627\n",
      "Epoch 481/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0041 - val_loss: 2.0609\n",
      "Epoch 482/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.9802 - val_loss: 2.0588\n",
      "Epoch 483/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0114 - val_loss: 2.0567\n",
      "Epoch 484/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0020 - val_loss: 2.0550\n",
      "Epoch 485/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.9980 - val_loss: 2.0534\n",
      "Epoch 486/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.9985 - val_loss: 2.0513\n",
      "Epoch 487/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0062 - val_loss: 2.0491\n",
      "Epoch 488/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0014 - val_loss: 2.0471\n",
      "Epoch 489/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.9743 - val_loss: 2.0455\n",
      "Epoch 490/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9688 - val_loss: 2.0440\n",
      "Epoch 491/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9757 - val_loss: 2.0430\n",
      "Epoch 492/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.9804 - val_loss: 2.0426\n",
      "Epoch 493/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9335 - val_loss: 2.0427\n",
      "Epoch 494/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.9462 - val_loss: 2.0429\n",
      "Epoch 495/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9524 - val_loss: 2.0428\n",
      "Epoch 496/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.9396 - val_loss: 2.0429\n",
      "Epoch 497/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.9350 - val_loss: 2.0426\n",
      "Epoch 498/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9670 - val_loss: 2.0417\n",
      "Epoch 499/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.8916 - val_loss: 2.0409\n",
      "Epoch 500/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.9072 - val_loss: 2.0405\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense, Concatenate, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Datos de ejemplo\n",
    "data = {\n",
    "   'user_id': [6, 3, 7, 4, 6, 9, 2, 6, 7, 4, 3, 7, 7, 2, 5, 4, 1, 7, 5, 1, 4, 0, 9, 5, 8, 0, 9, 2, 6, 3, 8, 2, 4, 2, 6, 4, 8, 6, 1, 3, 8, 1, 9, 8, 9, 4, 1, 3, 6, 7],\n",
    "   'book_id': [14, 2, 13, 16, 3, 17, 7, 3, 1, 5, 9, 3, 17, 11, 1, 9, 3, 13, 15, 14, 7, 13, 7, 15, 12, 17, 14, 12, 8, 14, 12, 0, 6, 8, 0, 11, 7, 10, 18, 16, 7, 2, 2, 0, 4, 9, 6, 8, 6, 8],\n",
    "   'rating': [4, 2, 1, 5, 3, 4, 3, 3, 1, 3, 5, 3, 1, 5, 2, 3, 1, 2, 2, 4, 5, 3, 1, 4, 5, 4, 5, 5, 3, 5, 4, 5, 3, 3, 4, 2, 2, 5, 1, 5, 4, 4, 4, 4, 4, 3, 2, 4, 1, 1]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['book_id'] = df['book_id'] - 1\n",
    "\n",
    "# Parámetros\n",
    "embedding_dim = 30\n",
    "l2_reg = 0.01\n",
    "dropout_rate = 0.5\n",
    "\n",
    "# Crear el modelo\n",
    "num_users = df['user_id'].nunique()\n",
    "num_items = df['book_id'].nunique()\n",
    "\n",
    "user_input = Input(shape=(1,), name='user_input')\n",
    "item_input = Input(shape=(1,), name='item_input')\n",
    "\n",
    "user_embedding = Embedding(input_dim=num_users, output_dim=embedding_dim, \n",
    "                           embeddings_regularizer=l2(l2_reg), name='user_embedding')(user_input)\n",
    "item_embedding = Embedding(input_dim=num_items, output_dim=embedding_dim, \n",
    "                           embeddings_regularizer=l2(l2_reg), name='item_embedding')(item_input)\n",
    "\n",
    "# Flatten the embeddings\n",
    "user_vec = Flatten(name='user_flatten')(user_embedding)\n",
    "item_vec = Flatten(name='item_flatten')(item_embedding)\n",
    "\n",
    "# Concatenate user and item vectors\n",
    "concat = Concatenate()([user_vec, item_vec])\n",
    "\n",
    "# Hidden layers with Dropout\n",
    "dense_1 = Dense(32, activation='relu')(concat)\n",
    "dropout_1 = Dropout(dropout_rate)(dense_1)\n",
    "#dense_2 = Dense(64, activation='relu')(dropout_1)\n",
    "#dropout_2 = Dropout(dropout_rate)(dense_2)\n",
    "output = Dense(1)(dense_1)\n",
    "\n",
    "# Crear el modelo\n",
    "model = Model(inputs=[user_input, item_input], outputs=output)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mean_squared_error')\n",
    "\n",
    "# Preparar los datos para el entrenamiento\n",
    "X = [df['user_id'].values, df['book_id'].values]\n",
    "y = df['rating'].values\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X, y, epochs=500, batch_size=32, verbose=1, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Graficar el loss de entrenamiento y validación\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Train vs Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating\n",
       "0        6       13       4\n",
       "1        3        1       2\n",
       "2        7       12       1\n",
       "3        4       15       5\n",
       "4        6        2       3"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Predicted rating for user 1 and item 3: 1.8583555221557617\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node functional_6_1/user_embedding_1/GatherV2 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\asyncio\\windows_events.py\", line 321, in run_forever\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\asyncio\\events.py\", line 84, in _run\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_26820\\1451532105.py\", line 17, in <module>\n\n  File \"C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_26820\\1451532105.py\", line 8, in candidate_generation\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 512, in predict\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 208, in one_step_on_data_distributed\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 198, in one_step_on_data\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 96, in predict_step\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 901, in __call__\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 175, in call\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 171, in _run_through_graph\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 560, in call\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 901, in __call__\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py\", line 140, in call\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\ops\\numpy.py\", line 4918, in take\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py\", line 1967, in take\n\nindices[0,0] = 100 is not in [0, 10)\n\t [[{{node functional_6_1/user_embedding_1/GatherV2}}]] [Op:__inference_one_step_on_data_distributed_2062303]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[115], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Generar recomendaciones\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m):\n\u001b[1;32m---> 18\u001b[0m     top_items \u001b[38;5;241m=\u001b[39m candidate_generation(i, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop 3 recommendations for user \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtop_items\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[115], line 8\u001b[0m, in \u001b[0;36mcandidate_generation\u001b[1;34m(user_id, top_k)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcandidate_generation\u001b[39m(user_id, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m      7\u001b[0m     all_items \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(num_items)\n\u001b[1;32m----> 8\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict([np\u001b[38;5;241m.\u001b[39marray([user_id] \u001b[38;5;241m*\u001b[39m num_items), all_items])\n\u001b[0;32m      9\u001b[0m     top_items \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(predictions\u001b[38;5;241m.\u001b[39mflatten())[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][:top_k]\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m top_items\n",
      "File \u001b[1;32mc:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node functional_6_1/user_embedding_1/GatherV2 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\asyncio\\windows_events.py\", line 321, in run_forever\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\asyncio\\events.py\", line 84, in _run\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_26820\\1451532105.py\", line 17, in <module>\n\n  File \"C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_26820\\1451532105.py\", line 8, in candidate_generation\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 512, in predict\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 208, in one_step_on_data_distributed\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 198, in one_step_on_data\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 96, in predict_step\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 901, in __call__\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 175, in call\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 171, in _run_through_graph\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 560, in call\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 901, in __call__\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py\", line 140, in call\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\ops\\numpy.py\", line 4918, in take\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py\", line 1967, in take\n\nindices[0,0] = 100 is not in [0, 10)\n\t [[{{node functional_6_1/user_embedding_1/GatherV2}}]] [Op:__inference_one_step_on_data_distributed_2062303]"
     ]
    }
   ],
   "source": [
    "# Función para predecir las calificaciones\n",
    "def predict_rating(user_id, item_id):\n",
    "    return model.predict([np.array([user_id]), np.array([item_id])])[0][0]\n",
    "\n",
    "# Generación de candidatos\n",
    "def candidate_generation(user_id, top_k=5):\n",
    "    all_items = np.arange(num_items)\n",
    "    predictions = model.predict([np.array([user_id] * num_items), all_items])\n",
    "    top_items = np.argsort(predictions.flatten())[::-1][:top_k]\n",
    "    return top_items\n",
    "\n",
    "# Prueba de la predicción\n",
    "pred_rating = predict_rating(1, 1)\n",
    "print(f\"Predicted rating for user 1 and item 3: {pred_rating}\")\n",
    "\n",
    "# Generar recomendaciones\n",
    "for i in range(100, 200):\n",
    "    top_items = candidate_generation(i, top_k=5)\n",
    "    print(f\"Top 3 recommendations for user {i}: {top_items}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_101",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
