{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def tokenize_dataset(dataset):\n",
    "    encoded = tokenizer(\n",
    "        dataset[\"sentence1\"],\n",
    "        dataset[\"sentence2\"],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors='np',\n",
    "    )\n",
    "    return encoded.data\n",
    "\n",
    "tokenized_datasets = {\n",
    "    split: tokenize_dataset(raw_datasets[split]) for split in raw_datasets.keys()\n",
    "}\n",
    "train_tokens = tokenized_datasets['train']['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = 'bert-base-cased'\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
    "\n",
    "batch_size = 8\n",
    "num_epochs = 3\n",
    "num_train_steps = (len(train_tokens) // batch_size) * num_epochs\n",
    "lr_scheduler = PolynomialDecay(\n",
    "    initial_learning_rate=5e-5,\n",
    "    end_learning_rate=0.,\n",
    "    decay_steps=num_train_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\optimizers\\__init__.py:317: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not interpret optimizer identifier: <keras.src.optimizers.adam.Adam object at 0x000001E73F5737D0>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[0;32m      3\u001b[0m opt \u001b[38;5;241m=\u001b[39m Adam(learning_rate\u001b[38;5;241m=\u001b[39mlr_scheduler)\n\u001b[1;32m----> 4\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mloss, optimizer\u001b[38;5;241m=\u001b[39mopt)\n",
      "File \u001b[1;32mc:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:1563\u001b[0m, in \u001b[0;36mTFPreTrainedModel.compile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, weighted_metrics, run_eagerly, steps_per_execution, **kwargs)\u001b[0m\n\u001b[0;32m   1561\u001b[0m \u001b[38;5;66;03m# This argument got renamed, we need to support both versions\u001b[39;00m\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps_per_execution\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m parent_args:\n\u001b[1;32m-> 1563\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m   1564\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m   1565\u001b[0m         loss\u001b[38;5;241m=\u001b[39mloss,\n\u001b[0;32m   1566\u001b[0m         metrics\u001b[38;5;241m=\u001b[39mmetrics,\n\u001b[0;32m   1567\u001b[0m         loss_weights\u001b[38;5;241m=\u001b[39mloss_weights,\n\u001b[0;32m   1568\u001b[0m         weighted_metrics\u001b[38;5;241m=\u001b[39mweighted_metrics,\n\u001b[0;32m   1569\u001b[0m         run_eagerly\u001b[38;5;241m=\u001b[39mrun_eagerly,\n\u001b[0;32m   1570\u001b[0m         steps_per_execution\u001b[38;5;241m=\u001b[39msteps_per_execution,\n\u001b[0;32m   1571\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1572\u001b[0m     )\n\u001b[0;32m   1573\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1574\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m   1575\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m   1576\u001b[0m         loss\u001b[38;5;241m=\u001b[39mloss,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1582\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1583\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\optimizers\\__init__.py:335\u001b[0m, in \u001b[0;36mget\u001b[1;34m(identifier, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get(\n\u001b[0;32m    331\u001b[0m         config,\n\u001b[0;32m    332\u001b[0m         use_legacy_optimizer\u001b[38;5;241m=\u001b[39muse_legacy_optimizer,\n\u001b[0;32m    333\u001b[0m     )\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 335\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    336\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not interpret optimizer identifier: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midentifier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    337\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret optimizer identifier: <keras.src.optimizers.adam.Adam object at 0x000001E73F5737D0>"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "opt = Adam(learning_rate=lr_scheduler)\n",
    "model.compile(loss=loss, optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      2\u001b[0m     tokenized_datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      3\u001b[0m     np\u001b[38;5;241m.\u001b[39marray(raw_datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]), \n\u001b[0;32m      4\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(tokenized_datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m], np\u001b[38;5;241m.\u001b[39marray(raw_datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])),\n\u001b[0;32m      5\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m      6\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[0;32m      7\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:1229\u001b[0m, in \u001b[0;36mTFPreTrainedModel.fit\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(keras\u001b[38;5;241m.\u001b[39mModel\u001b[38;5;241m.\u001b[39mfit)\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1228\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m convert_batch_encoding(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py:3978\u001b[0m, in \u001b[0;36mModel._assert_compile_was_called\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3972\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_assert_compile_was_called\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   3973\u001b[0m     \u001b[38;5;66;03m# Checks whether `compile` has been called. If it has been called,\u001b[39;00m\n\u001b[0;32m   3974\u001b[0m     \u001b[38;5;66;03m# then the optimizer is set. This is different from whether the\u001b[39;00m\n\u001b[0;32m   3975\u001b[0m     \u001b[38;5;66;03m# model is compiled\u001b[39;00m\n\u001b[0;32m   3976\u001b[0m     \u001b[38;5;66;03m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[39;00m\n\u001b[0;32m   3977\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_compiled:\n\u001b[1;32m-> 3978\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   3979\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must compile your model before \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3980\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining/testing. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3981\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `model.compile(optimizer, loss)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3982\u001b[0m         )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    tokenized_datasets['train'],\n",
    "    np.array(raw_datasets['train']['label']), \n",
    "    validation_data=(tokenized_datasets['validation'], np.array(raw_datasets['validation']['label'])),\n",
    "    batch_size=8,\n",
    "    epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node tf_bert_for_sequence_classification/bert/embeddings/assert_less/Assert/Assert defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\asyncio\\windows_events.py\", line 321, in run_forever\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\asyncio\\events.py\", line 84, in _run\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_24624\\1108148874.py\", line 1, in <module>\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1249, in predict\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 2650, in predict\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 2436, in predict_function\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 2421, in step_function\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 2409, in run_step\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 2377, in predict_step\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 588, in __call__\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer.py\", line 1136, in __call__\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1734, in run_call_with_unpacked_inputs\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 1746, in call\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer.py\", line 1136, in __call__\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1734, in run_call_with_unpacked_inputs\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 887, in call\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer.py\", line 1136, in __call__\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 180, in call\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 181, in call\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\transformers\\tf_utils.py\", line 190, in check_embeddings_within_bounds\n\nassertion failed: [The maximum value of input_ids (Tensor(\\\"tf_bert_for_sequence_classification/bert/embeddings/Max:0\\\", shape=(), dtype=int32)) must be smaller than the embedding layer\\'s input dimension (28996). The likely cause is some problem at tokenization time.] [Condition x < y did not hold element-wise:] [x (IteratorGetNext:1) = ] [[101 2002 2056...]...] [y (tf_bert_for_sequence_classification/bert/embeddings/Cast/x:0) = ] [28996]\n\t [[{{node tf_bert_for_sequence_classification/bert/embeddings/assert_less/Assert/Assert}}]] [Op:__inference_predict_function_5415]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(tokenized_datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      2\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(preds)\n\u001b[0;32m      3\u001b[0m class_preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(probabilities, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:1249\u001b[0m, in \u001b[0;36mTFPreTrainedModel.predict\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(keras\u001b[38;5;241m.\u001b[39mModel\u001b[38;5;241m.\u001b[39mpredict)\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1248\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m convert_batch_encoding(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node tf_bert_for_sequence_classification/bert/embeddings/assert_less/Assert/Assert defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\asyncio\\windows_events.py\", line 321, in run_forever\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\asyncio\\events.py\", line 84, in _run\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_24624\\1108148874.py\", line 1, in <module>\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1249, in predict\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 2650, in predict\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 2436, in predict_function\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 2421, in step_function\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 2409, in run_step\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 2377, in predict_step\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 588, in __call__\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer.py\", line 1136, in __call__\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1734, in run_call_with_unpacked_inputs\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 1746, in call\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer.py\", line 1136, in __call__\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1734, in run_call_with_unpacked_inputs\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 887, in call\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer.py\", line 1136, in __call__\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 180, in call\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 181, in call\n\n  File \"c:\\Users\\usuario\\anaconda3\\envs\\env_101\\Lib\\site-packages\\transformers\\tf_utils.py\", line 190, in check_embeddings_within_bounds\n\nassertion failed: [The maximum value of input_ids (Tensor(\\\"tf_bert_for_sequence_classification/bert/embeddings/Max:0\\\", shape=(), dtype=int32)) must be smaller than the embedding layer\\'s input dimension (28996). The likely cause is some problem at tokenization time.] [Condition x < y did not hold element-wise:] [x (IteratorGetNext:1) = ] [[101 2002 2056...]...] [y (tf_bert_for_sequence_classification/bert/embeddings/Cast/x:0) = ] [28996]\n\t [[{{node tf_bert_for_sequence_classification/bert/embeddings/assert_less/Assert/Assert}}]] [Op:__inference_predict_function_5415]"
     ]
    }
   ],
   "source": [
    "preds = model.predict(tokenized_datasets['validation'])['logits']\n",
    "probabilities = tf.nn.softmax(preds)\n",
    "class_preds = np.argmax(probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_101",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
