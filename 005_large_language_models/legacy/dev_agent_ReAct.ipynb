{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "with open(\".env.json\", \"r\") as f_in:\n",
    "    env_json: dict = json.load(f_in)\n",
    "    for key, value in env_json.items():\n",
    "        os.environ[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-06 15:40:40.694069-05:00: Modelo EnumGenAIModelsIdsOpenAI.MODEL_CHAT_GPT_3_5_TURBO construido\n",
      "True\n",
      "2024-02-06 15:40:40.694069-05:00: Invocando modelo EnumGenAIModelsIdsOpenAI.MODEL_CHAT_GPT_3_5_TURBO con Hola\n",
      "¡Hola! ¿En qué puedo ayudarte hoy?\n"
     ]
    }
   ],
   "source": [
    "# Instancia de modelo a reusarse\n",
    "from framework_genai.GenAIMemory import GenAIMemory, EnumMemoryType\n",
    "from framework_genai.GenAILLM import GenAILLM, EnumGenAIPlatforms, EnumGenAIModelsIdsOpenAI\n",
    "from framework_genai.LoggingAndTelemetry import EnumLogs\n",
    "import os\n",
    "\n",
    "ai_prefix = \"Human\"\n",
    "human_prefix = \"Assistant\"\n",
    "\n",
    "gen_ai_llm = GenAILLM(\n",
    "    platform = EnumGenAIPlatforms.PLATFORM_OPENAI,\n",
    "    model_id = EnumGenAIModelsIdsOpenAI.MODEL_CHAT_GPT_3_5_TURBO,\n",
    "    parameters_inference = {\n",
    "        'max_tokens': 512, \n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": 0.9\n",
    "    },\n",
    "    ai_prefix = ai_prefix,\n",
    "    human_prefix = human_prefix,\n",
    "    component_memory=GenAIMemory(EnumMemoryType.MEMORY_CHAT_BUFFER, ai_prefix, human_prefix),\n",
    "    platform_configuration = {\n",
    "        \"OPENAI_API_KEY\": os.environ[\"OPENAI_API_KEY\"]\n",
    "    },\n",
    "    verify_ssl=True,\n",
    "    verbose_level=EnumLogs.LOG_LEVEL_DEBUG\n",
    ")\n",
    "print(gen_ai_llm.llm_model.verbose)\n",
    "print(gen_ai_llm.invoke(\"Hola\", return_completion_only=True, save_in_memory=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from framework_genai.GenAIOutputParser import GenAIOutputParser\n",
    "gen_ai_output_parser = GenAIOutputParser([\n",
    "    {\n",
    "        \"name\": \"reasoning\",\n",
    "        \"description\": \"razonamiento detras de la respuesta\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"respuesta\",\n",
    "        \"description\": \"respuesta final concreta y concisa\"\n",
    "    },\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{system_prompt}. \n",
      "    Tienes acceso a las siguientes herramientas:\n",
      "    {tools}\n",
      "\n",
      "    Este es un contexto adicional: <context>{context}</context>\n",
      "\n",
      "    Utilice el siguiente formato puesto en la etiqueta <formato> para generar tu respuesta final:\n",
      "    <formato>\n",
      "    Question: la pregunta de entrada que debes responder\n",
      "    Thought: siempre debes pensar qué hacer\n",
      "    Action: la acción a tomar, debe ser una de [{tool_names}]\n",
      "    Action Input: la entrada de la acción\n",
      "    Observation: el resultado de la acción\n",
      "    ... (la secuencia Thought,Action,Action Input y Observation puede repetirse tantas veces como sea necesario)\n",
      "    Thought: Ahora sé la respuesta final\n",
      "    Final Answer: la respuesta final a la pregunta de entrada original, es un string que estará en el formato de las siguientes instrucciones: {format_instructions}\n",
      "    </formato>\n",
      "\n",
      "    Ahora inicia. Te pasaré un Question del que deberás continuar con la cadena de pensamientos. Recuerda utilizar saltos de línea para denotar cada Thought/Action/Action Input/Observation o similar.\n",
      "    Question: {input}\n",
      "    Thought: {agent_scratchpad}\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from framework_genai.GenAIPrompt import EnumPromptsBase\n",
    "print(EnumPromptsBase.PROMPT_BASE_REACT_CHAT.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mNecesito buscar quién es el presidente de Ecuador y su edad actual. Puedo usar la herramienta de Buscador para encontrar esta información. \n",
      "Action: Buscador\n",
      "Action Input: \"presidente de Ecuador\"\u001b[0m\u001b[36;1m\u001b[1;3mDaniel Noboa\u001b[0m\u001b[32;1m\u001b[1;3mAhora que tengo el nombre del presidente de Ecuador, puedo buscar su edad actual. Utilizaré la herramienta de Buscador nuevamente para encontrar esta información.\n",
      "Action: Buscador\n",
      "Action Input: \"edad de Daniel Noboa\"\u001b[0m\u001b[36;1m\u001b[1;3m30 de noviembre de 1987 (edad 36 años), Miami, Florida\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mAhora que tengo la fecha de nacimiento de Daniel Noboa, puedo calcular su edad actual dividiendo el año actual menos el año de nacimiento entre 2. Utilizaré la herramienta de Python_REPL para realizar este cálculo.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: print((2023 - 1987) / 2)\u001b[0m\u001b[38;5;200m\u001b[1;3m18.0\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mAhora sé la respuesta final. El presidente de Ecuador es Daniel Noboa y su edad dividida por 2 es 18 años.\n",
      "\n",
      "Final Answer:\n",
      "```json\n",
      "{\n",
      "\t\"reasoning\": \"Utilicé la herramienta de Buscador para encontrar el nombre del presidente de Ecuador, Daniel Noboa. Luego, utilicé la misma herramienta para encontrar su fecha de nacimiento y calcular su edad actual dividiendo el año actual menos el año de nacimiento entre 2.\",\n",
      "\t\"respuesta\": \"El presidente de Ecuador es Daniel Noboa y su edad dividida por 2 es 18 años.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': '¿Quién es el presidente de ecuador? ¿Cuánto es su edad dividido para 2?', 'context': '', 'output': '```json\\n{\\n\\t\"reasoning\": \"Utilicé la herramienta de Buscador para encontrar el nombre del presidente de Ecuador, Daniel Noboa. Luego, utilicé la misma herramienta para encontrar su fecha de nacimiento y calcular su edad actual dividiendo el año actual menos el año de nacimiento entre 2.\",\\n\\t\"respuesta\": \"El presidente de Ecuador es Daniel Noboa y su edad dividida por 2 es 18 años.\"\\n}\\n```', 'intermediate_steps': [(AgentAction(tool='Buscador', tool_input='presidente de Ecuador', log='Necesito buscar quién es el presidente de Ecuador y su edad actual. Puedo usar la herramienta de Buscador para encontrar esta información. \\nAction: Buscador\\nAction Input: \"presidente de Ecuador\"'), 'Daniel Noboa'), (AgentAction(tool='Buscador', tool_input='edad de Daniel Noboa', log='Ahora que tengo el nombre del presidente de Ecuador, puedo buscar su edad actual. Utilizaré la herramienta de Buscador nuevamente para encontrar esta información.\\nAction: Buscador\\nAction Input: \"edad de Daniel Noboa\"'), '30 de noviembre de 1987 (edad 36 años), Miami, Florida'), (AgentAction(tool='Python_REPL', tool_input='print((2023 - 1987) / 2)', log='Ahora que tengo la fecha de nacimiento de Daniel Noboa, puedo calcular su edad actual dividiendo el año actual menos el año de nacimiento entre 2. Utilizaré la herramienta de Python_REPL para realizar este cálculo.\\n\\nAction: Python_REPL\\nAction Input: print((2023 - 1987) / 2)'), '18.0\\n')]}\n"
     ]
    }
   ],
   "source": [
    "from framework_genai.GenAIAgent import GenAIAgent, EnumGenAIAgentType\n",
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "import random\n",
    "from langchain.agents import Tool\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "\n",
    "@tool(\"lower_case\", return_direct=False)\n",
    "def to_lower_case(input:str) -> str:\n",
    "    \"\"\"Returns the input as all lower case.\"\"\"\n",
    "    return input.lower()\n",
    "\n",
    "@tool(\"random_number\", return_direct=False)\n",
    "def random_number_maker(input:str) -> str:\n",
    "    \"\"\"Returns a random number between 0-100. input the word 'random'\"\"\"\n",
    "    return random.randint(0, 100)\n",
    "\n",
    "python_repl_tool = PythonREPLTool()\n",
    "search = GoogleSerperAPIWrapper()\n",
    "tools = [\n",
    "    to_lower_case,\n",
    "    random_number_maker,\n",
    "    python_repl_tool,\n",
    "    Tool(\n",
    "        name=\"Buscador\",\n",
    "        func=search.run,\n",
    "        description=\"útil cuando deseamos buscar algo\"\n",
    "    )\n",
    "]\n",
    "\n",
    "agent_react = GenAIAgent(\n",
    "    system_prompt=\"Eres un asistente muy util\",\n",
    "    agent_type=EnumGenAIAgentType.AGENT_TYPE_REACT,\n",
    "    gen_ai_output_parser=gen_ai_output_parser,\n",
    "    gen_ai_llm=gen_ai_llm,\n",
    "    tools=tools,\n",
    "    state={},\n",
    "    name=\"AgenteDemo\",\n",
    "    verbose_level=EnumLogs.LOG_LEVEL_DEBUG\n",
    ")\n",
    "print(agent_react.agent_executor.verbose)\n",
    "agent_result = agent_react.invoke({\n",
    "    \"input\": \"¿Quién es el presidente de ecuador? ¿Cuánto es su edad dividido para 2?\",\n",
    "    \"context\": \"\"\n",
    "})\n",
    "print(agent_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
