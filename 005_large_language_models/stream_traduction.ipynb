{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lib.framework_genai.GenAILLM import EnumGenAIModelsIdsOpenAI, EnumGenAIPlatforms, GenAILLM\n",
    "from lib.framework_genai.GenAIMemory import EnumMemoryType, GenAIMemory\n",
    "from lib.framework_genai.LoggingAndTelemetry import EnumLogs\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-10 23:56:01.785224-05:00: Modelo EnumGenAIModelsIdsOpenAI.MODEL_CHAT_GPT_4 construido\n"
     ]
    }
   ],
   "source": [
    "ai_prefix = \"Assistant\"\n",
    "human_prefix = \"Human\"\n",
    "verbose_level:EnumLogs = EnumLogs.LOG_LEVEL_DEBUG\n",
    "\n",
    "gen_ai_llm = GenAILLM(\n",
    "    platform = EnumGenAIPlatforms.PLATFORM_OPENAI,\n",
    "    model_id = EnumGenAIModelsIdsOpenAI.MODEL_CHAT_GPT_4,\n",
    "    parameters_inference = {\n",
    "        'max_tokens': 4096, \n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": 0.1\n",
    "    },\n",
    "    ai_prefix = ai_prefix,\n",
    "    human_prefix = human_prefix,\n",
    "    component_memory=GenAIMemory(EnumMemoryType.MEMORY_CHAT_BUFFER, ai_prefix, human_prefix),\n",
    "    platform_configuration = {\n",
    "        \"OPENAI_API_KEY\": os.environ[\"OPENAI_API_KEY\"]\n",
    "    },\n",
    "    verify_ssl=True,\n",
    "    verbose_level=verbose_level\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-10 22:45:51.082694-05:00: Invocando modelo EnumGenAIModelsIdsOpenAI.MODEL_CHAT_GPT_3_5_TURBO_16k con hola\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'¡Hola! ¿En qué puedo ayudarte hoy?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_ai_llm.invoke(\"hola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "input_file_path = \"./temp/source_real.txt\"\n",
    "output_file_path = \"./temp/source_migrated.py\"\n",
    "\n",
    "# Lee el contenido del archivo de entrada\n",
    "with open(input_file_path, 'r', encoding='utf-8') as input_file:\n",
    "    content = input_file.read()\n",
    "\n",
    "# Escribe el contenido en el archivo de salida\n",
    "with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "    output_file.write(\"\")\n",
    "\n",
    "async for chunk in gen_ai_llm.llm_model.astream(f\"\"\"Genera un ensayo o mas bien una documentación extensa en markdown del siguiente código:\n",
    "{content}\"\"\"):\n",
    "    \n",
    "    with open(output_file_path, 'a', encoding='utf-8') as output_file:\n",
    "        output_file.write(chunk.content)\n",
    "    # print(chunk.content, end=\"|\", flush=True)\n",
    "    # sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Realiza una migración del siguiente código en javascript\n",
    "Hacia python. No agreges preámbulo, tampoco ```python. Solo da el código en python listo para ejecutarse. Utiliza la librería pygame. Importala al inicio y realiza todas las modificaciones necesarias para que este juego de tetris se renderice como en la versión original de javascript, pero con colores. Verifica que existan todas las funciones y el juego pueda ejecutarse. Segun la pieza en pieces, dale un color diferente. Establece los ticks de pygame a 10 al final.\n",
    "Recuerda que en tetris cuando se llena una fila, esta debe borrarse\n",
    "                                                \n",
    "El código es:\n",
    "{content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agrega javadocs al siguiente código. por ejemplo un javadoc es:\n",
    "/**\n",
    "     * Constructor de la clase Cuenta.\n",
    "     *\n",
    "     * @param numeroCuenta el número de la cuenta\n",
    "     * @param saldoInicial el saldo inicial de la cuenta\n",
    "     */\n",
    "                                                \n",
    "Solo pasa el código tal cual, agregando la documentación. No agregues preámbulo ni notas adicionales. Solo da el código\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agrega pruebas unitarias al siguiente código\n",
    "                                                \n",
    "No agregues preámbulo ni notas adicionales. Solo da el código\n",
    "                                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
